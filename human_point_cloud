//much of this was pulled from daniel schiffman's examples in processing for kinect
//I added in parts to create some dots and line alongside the person AND syphon it into touch designer for further graphics stuff

// Daniel Shiffman
// Kinect Point Cloud example

// https://github.com/shiffman/OpenKinect-for-Processing
// http://shiffman.net/p5/kinect/

import org.openkinect.freenect.*;
import org.openkinect.processing.*;
import codeanticode.syphon.*;

// Kinect Library object
Kinect kinect;
SyphonServer server;

//Mover[] movers = new Mover[100];

//Attractor a;

// Angle for rotation
float r = radians(160);
//float s = radians(0);

// We'll use a lookup table so that we don't have to repeat the math over and over
float[] depthLookUp = new float[2048];

void setup() {
  frameRate(24);
  // Rendering in P3D
  //for tim
  // size(2400, 400, P3D);
  size(1280, 900, P3D);
  kinect = new Kinect(this);
  kinect.initDepth();
  server = new SyphonServer(this, "Processing Syphon");
  
  // Lookup table for all possible depth values (0 - 2047)
  for (int i = 0; i < depthLookUp.length; i++) {
    depthLookUp[i] = rawDepthToMeters(i);
  }
  
  //for attractors and movers
 // for (int i = 0; i < movers.length; i++) {
//    movers[i] = new Mover(random(0.1,1),3000,3000); 
//  }
//  a = new Attractor();
}

void draw() {

  background(0,0,0,.1);
  // Get the raw depth as array of integers
  int[] depth = kinect.getRawDepth();

  // We're just going to calculate and draw every 4th pixel (equivalent of 160x120)
  int skip = 2;

  // Translate and rotate
  translate(width/2, height/2);
  //rotateX(r);
  rotateY(r);
  //rotateY(s);
  //rotateZ(r);  
  // Nested for loop that initializes x and y pixels and, for those less than the
  // maximum threshold and at every skiping point, the offset is caculated to map
  // them on a plane instead of just a line
  for (int x = 0; x < kinect.width; x += skip) {
    for (int y = 0; y < kinect.height; y += skip) {
      int offset = x + y*kinect.width;
      
      // Convert kinect data to world xyz coordinate
      int rawDepth = depth[offset];    PVector v = depthToWorld(x, y, rawDepth);
      
      ///if (v < kinect.width/2) {
        //stroke(204, 102, 0);
        //}
        //stroke(0, 102, 0);
      stroke(255,255,255);
      pushMatrix();
      // Scale up by 400
      float factor = 500;
      translate(v.x*factor, v.y*factor, factor-v.z*factor);
      // Draw a point
      point(0,0);
      popMatrix();
    }
  }

  // Rotate
  r += 0.0f;
  //s += -0.01f;
  server.sendScreen();
  
//saveFrame("output3/dancer_####.png");
  
  //for movers and attractors
 // a.display();

//  for (int i = 0; i < movers.length; i++) {
//    PVector force = a.attract(movers[i]);
//    movers[i].applyForce(force);

//    movers[i].update();
//    movers[i].display();
//  }
}

// These functions come from: http://graphics.stanford.edu/~mdfisher/Kinect.html
float rawDepthToMeters(int depthValue) {
  if (depthValue < 950) {
    return (float)(1.0 / ((double)(depthValue) * -0.0030711016 + 3.3309495161 ));
  }
  return 0.0f;
}

// Only needed to make sense of the ouput depth values from the kinect
PVector depthToWorld(int x, int y, int depthValue) {

  final double fx_d = 1.0 / 5.9421434211923247e+02;
  final double fy_d = 1.0 / 5.9104053696870778e+02;
  final double cx_d = 3.3930780975300314e+02;
  final double cy_d = 2.4273913761751615e+02;

// Drawing the result vector to give each point its three-dimensional space
  PVector result = new PVector();
  double depth =  depthLookUp[depthValue];//rawDepthToMeters(depthValue);
  result.x = (float)((x - cx_d) * depth * fx_d);
  result.y = (float)((y - cy_d) * depth * fy_d);
  result.z = (float)(depth);
 

  return result;
}

